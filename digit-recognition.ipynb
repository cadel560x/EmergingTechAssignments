{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition Script\n",
    "This script tries to recognize handwritten images previous training against the MNIST dataset. The main feature of this script is that aims to create sequential neural networks using the Keras library.\n",
    "\n",
    "\n",
    "## Structure\n",
    "This script is conceived as an interactive script using a menu-item scheme. Structured in six diffrent modules or functions, each function responds to one item displayed in the menu.\n",
    "\n",
    "The script can be divided in three big sections:\n",
    "* Library/module imports and global variables\n",
    "* Function definitions\n",
    "* Menu\n",
    "\n",
    "### Library/Module Imports and Global Variables\n",
    "#### Imports\n",
    "First section of the script consists in importing the required libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # For image debugging purposes\n",
    "\n",
    "import sklearn.preprocessing as pre # Input preprocessing\n",
    "import numpy as np # Utility library \n",
    "import keras as kr # Tensorflow high-level neural networks API\n",
    "import gzip # Uncompressing MNIST files\n",
    "\n",
    "from keras.models import load_model # Loading neural networks from HDF5 files\n",
    "from PIL import Image # Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Variables\n",
    "After imports, the global variables are defined or declared\n",
    "* enconder: it converts multi-class labels to binary labels (belong or does not belong to the class). Since our classes are well known, decimal digits, the enconder can be defined early.\n",
    "* model: it represent the neural network model to load/create/train/test or validate\n",
    "This variables are read and modified from various functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f: # Uncompress MNIST test labels file\n",
    "\t\ttest_lbl = f.read()\n",
    "test_lbl = np.array(list(test_lbl[ 8:])).astype(np.uint8) # Set the classes as input for the enconder\n",
    "encoder = pre.LabelBinarizer() # Deefine and set the encoder\n",
    "encoder.fit(test_lbl) \n",
    "\n",
    "# Global model variable\n",
    "model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions\n",
    "Next are the definition of the different functions of this script\n",
    "\n",
    "#### Load Model Function\n",
    "It prompts the user for an HDF5 file that contains a Keras neural network model. That model is going to be stored in the global variable *model*. As a last step it displays a summary of the model, so the user can have an idea about the loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "\tglobal model\n",
    "\tfilename = input(\"Please enter a HDF5 file to load: \")\n",
    "\tmodel = load_model(filename)\n",
    "\t# DEBUG print(type(model))\n",
    "\tmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Function\n",
    "This function creates and configures a model. It overwrites the *model* global variable so any previous model stored in this variable is destroyed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure():\n",
    "\tglobal model\n",
    "\tif model: # Checks if a model already exists\n",
    "\t\tconfirmation = input(\"\\nThe current model is about to be destroyed. Continue? (y/n) \")\n",
    "\t\tif confirmation == \"y\":\n",
    "\t\t\tdel model # Wipes any previous model\n",
    "\t\telif confirmation == \"n\":\n",
    "\t\t\treturn # Exits to main menu if user decides to keep the current model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predefined neural network type is sequential, meaning one layer of neurons after another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tmodel = kr.models.Sequential() # Defines the model as a sequential neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum amount of neuron layers created by this script is three:\n",
    "* input layer: defaults to 784 neurons\n",
    "* hidden layer(s) : defaults to 600 neurons\n",
    "* output layer: has 10 neurons mandatory ( digits 0 to 9 )\n",
    "\n",
    "This script allow the user to input the amount of neurons and the activation function for each layer. The [activation functions](https://keras.io/activations/) are the ones specified in the Keras documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tprint(\"Model options\")\n",
    "\t\n",
    "    # First layer setup\n",
    "\tinput_str = input(\"\\nFirst layer: how many input neurons? (default: 784) \")\n",
    "\tinital_neurons = 784\n",
    "\tif not len(input_str) == 0:\n",
    "\t\ttry:\n",
    "\t\t\tinital_neurons = int(input_str)\n",
    "\t\t\tif inital_neurons <= 0:\n",
    "\t\t\t\traise ValueError('InvalidInput')\n",
    "\t\texcept ValueError:\n",
    "\t\t\t# handle input error or assign default for invalid input\n",
    "\t\t\tprint('First layer neurons can\\'t be less or equal to zero')\n",
    "\n",
    "\t# Second layer setup\n",
    "\tneurons = 600\n",
    "\tinput_str = input(\"Second layer: how many neurons? (default: 600) \")\n",
    "\tif not len(input_str) == 0:\n",
    "\t\ttry:\n",
    "\t\t\tneurons = int(input_str)\n",
    "\t\t\tif neurons <= 0:\n",
    "\t\t\t\traise ValueError('InvalidInput')\n",
    "\t\texcept ValueError:\n",
    "\t\t\t# handle input error or assign default for invalid input\n",
    "\t\t\tprint('Second layer neurons can\\'t be less or equal to zero')\n",
    "\t\n",
    "    # Second layer activation function input\n",
    "\tprint(\"Second layer: which activation function to use? (e.g. linear, sigmoid, elu, selu, relu, softplus, softmax)  \")\n",
    "\tprint(\"More activation functions at https://keras.io/activations/\")\n",
    "\tactivation_function = input()\n",
    "\t\n",
    "\t# First and second layers definition\n",
    "\tmodel.add(kr.layers.Dense(units=neurons, activation=activation_function, input_dim=inital_neurons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It uses a while loop to add layers and it stops when the user doesn't require to add more layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # While loop for adding more layers\n",
    "\tanswer = input(\"\\nAdd another layer? (y/n) \")\n",
    "\twhile answer == \"y\":\n",
    "\t\tneurons = 400 # After the second layer, neuron default value is 400\n",
    "\t\tinput_str = input(\"New layer: how many neurons? (default: 400) \")\n",
    "\t\tif not len(input_str) == 0:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tneurons = int(input_str)\n",
    "\t\t\t\tif neurons <= 0:\n",
    "\t\t\t\t\traise ValueError('InvalidInput')\n",
    "\t\t\texcept ValueError:\n",
    "\t\t\t\t# handle input error or assign default for invalid input\n",
    "\t\t\t\tprint('New layer neurons can\\'t be less or equal to zero')\n",
    "\t\t\n",
    "\t\tprint(\"New layer: which activation function to use? (e.g. linear, sigmoid, elu, selu, relu, softplus, softmax)  \")\n",
    "\t\tprint(\"More activation functions at https://keras.io/activations/\")\n",
    "\t\tactivation_function = input()\n",
    "\t\t\n",
    "\t\tmodel.add(kr.layers.Dense(units=neurons, activation=activation_function))\n",
    "\t\t\n",
    "\t\tanswer = input(\"\\nAdd another layer? (y/n) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output layer is predifined to have 10 neurons. The user only inputs the activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Output layer, it has 10 neurons mandatory\n",
    "\tprint(\"Last layer: it is set by default to 10 output neurons strictly\")\n",
    "\tprint(\"Last layer: which activation function to use? (e.g. linear, sigmoid, elu, selu, relu, softplus, softmax) \")\n",
    "\tprint(\"More activation functions at https://keras.io/activations/\")\n",
    "\tactivation_function = input()\n",
    "\tmodel.add(kr.layers.Dense(units=10, activation=activation_function))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the layers are define the script asks for compile options, the loss function and the optimizer. The [loss functions](https://github.com/keras-team/keras/blob/master/keras/losses.py) and the [optimizers](https://keras.io/optimizers/) are the ones specified by the Keras documentation. Then the script proceeds to compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tprint(\"\\nCompile options\")\n",
    "\tprint(\"Which loss function to use? (e.g. binary_crossentropy, categorical_crossentropy, mse, mae, mape, msle, kld, cosine) \")\n",
    "\tprint(\"More loss functions at https://github.com/keras-team/keras/blob/master/keras/losses.py\")\n",
    "\tloss_function = input()\n",
    "\t\n",
    "\tprint(\"\\nWhich optimizer? (e.g sgd, rmsprop, adam, adadelta, adagrad)\")\n",
    "\tprint(\"More optimizers at https://keras.io/optimizers/\")\n",
    "\toptimizer_value = input()\n",
    "    \n",
    "\tmodel.compile(loss=loss_function, optimizer=optimizer_value, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally a model of the just configured model is displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tmodel.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Function\n",
    "As its name suggests, this function trains a neural network stored in the global variable *model*. First checks that the global variable *model* is not empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "\tglobal model\n",
    "\tglobal encoder\n",
    "\t\n",
    "\tif not model:\n",
    "\t\tprint(\"Empty model. Please create/load a model first\")\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, it uncompress the training files containing the images of the MNIST handwritten numbers and their respective labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\twith gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "\t\ttrain_img = f.read()\n",
    "\n",
    "\twith gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "\t\ttrain_lbl = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The local variables *train_img* and *train_lbl* are defined. The variable *train_img* skips the first 16 header bytes of the images file and the proceeds to store the images as 60000 matrices of size 28 by 28 unsigned bytes. Each image is processed by the NOT bitwise operand, since the background and foreground of the MNIST are black and white, the scripts invert them to obtain a more common black foreground over white background image. Each matrix is divided by the scalar *255.0* to normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\ttrain_img = ~np.array(list(train_img[16:])).reshape(60000, 28, 28).astype(np.uint8) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The digits labels have a similar treatment. They are stored in the local variable *train_lbl*, skipping the first 8 hearder bytes of the labels file. Labels are stored in an unidimensional array of 1 row and 60000 columns of type unsinged bytes, each containing a label for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\ttrain_lbl =  np.array(list(train_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the images are \"flateen\" into a two-dimensional array of 60000 rows, each row is an image, and 784 unsigned byte columns, each column represents a pixel of the MNIST 28x28 image. This is done in order to match a single pixel with a single input neuron of the model. Also, for performance purposes avoided nested *for* loops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tinputs = train_img.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the labels, they are enconded in a multi-class binary categorization of the following format:\n",
    "* 0 is represented as the array \\[1, 0, 0, 0, 0, 0, 0, 0, 0, 0\\]\n",
    "* 1 is represented as the array \\[0, 1, 0, 0, 0, 0, 0, 0, 0, 0\\]\n",
    "* 2 is represented as the array \\[0, 0, 1, 0, 0, 0, 0, 0, 0, 0\\]\n",
    "* 3 is represented as the array \\[0, 0, 0, 1, 0, 0, 0, 0, 0, 0\\]\n",
    "* 4 is represented as the array \\[0, 0, 0, 0, 1, 0, 0, 0, 0, 0\\]\n",
    "* 5 is represented as the array \\[0, 0, 0, 0, 0, 1, 0, 0, 0, 0\\]\n",
    "* 6 is represented as the array \\[0, 0, 0, 0, 0, 0, 1, 0, 0, 0\\]\n",
    "* 7 is represented as the array \\[0, 0, 0, 0, 0, 0, 0, 1, 0, 0\\]\n",
    "* 8 is represented as the array \\[0, 0, 0, 0, 0, 0, 0, 0, 1, 0\\]\n",
    "* 9 is represented as the array \\[0, 0, 0, 0, 0, 0, 0, 0, 0, 1\\]\n",
    "\n",
    "There are 60000 labels for the 60000 training images, each label is enconded in the above fashion and passed to the last/output layer of 10 neurons when training an image, so with this technique the the neural network is instructed  if it has achivied or not the desired classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\toutputs = encoder.transform(train_lbl)\n",
    "\n",
    "\t# DEBUG print(\"outputs\", outputs, outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A summary of the model to be trained is displayed to the user, for verification and rememberance purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the script asks the users the training parameters:\n",
    "* epoch: an arbitrary cutoff, generally defined as \"one pass over the entire dataset\", used to separate training into distinct phases, which is useful for logging and periodic evaluation. Defaults to 2\n",
    "* batch size: generally approximates the distribution of the input data better than a single input. Defaults to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tepoch_input = 2\n",
    "\tinput_str = input(\"Train model: how many epochs? (default: 2) \")\n",
    "\tif not len(input_str) == 0:\n",
    "\t\ttry:\n",
    "\t\t\tepoch_input = int(input_str)\n",
    "\t\t\tif epoch_input <= 0:\n",
    "\t\t\t\traise ValueError('InvalidInput')\n",
    "\t\texcept ValueError:\n",
    "\t\t\t# handle input error or assign default for invalid input\n",
    "\t\t\tprint('Second layer neurons can\\'t be less or equal to zero')\n",
    "\t\t\t\n",
    "\tbatch_input = 100\n",
    "\tinput_str = input(\"Train model: batch size? (default: 100) \")\n",
    "\tif not len(input_str) == 0:\n",
    "\t\ttry:\n",
    "\t\t\tbatch_input = int(input_str)\n",
    "\t\t\tif batch_input <= 0:\n",
    "\t\t\t\traise ValueError('InvalidInput')\n",
    "\t\texcept ValueError:\n",
    "\t\t\t# handle input error or assign default for invalid input\n",
    "\t\t\tprint('Second layer neurons can\\'t be less or equal to zero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model training starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tmodel.fit(inputs, outputs, epochs=epoch_input, batch_size=batch_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model is trained, the script asks the user if the model should be saved into an HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tprint(\"\\nSave this model into a HDF5 file? (y/n) \")\n",
    "\tsave_file = input()\n",
    "\t\n",
    "\tif save_file == \"y\":\n",
    "\t\tsave()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Function\n",
    "This function is in charge of testing a model against MNIST image test set. As good practice, it checks if the model is not empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "\tglobal model\n",
    "\tglobal encoder\n",
    "\tglobal test_lbl\n",
    "\t\n",
    "\tif not model:\n",
    "\t\tprint(\"Empty model. Please create/load a model first\")\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it uncompress the image test file, and processes the images the same exact way the train function does: it skips the first 16 header bytes of the images file and the proceeds to store the images as 10000 matrices of size 28 by 28 unsigned bytes. Each image is processed by the NOT bitwise operand, since the background and foreground of the MNIST are black and white, the scripts invert them to obtain a more common black foreground over white background image. Each matrix is divided by the scalar 255.0 to normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\twith gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "\t\ttest_img = f.read()\n",
    "\t\t\n",
    "\ttest_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model summary is display to remind about the model that is going to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model starts predicting over the array of normalized flatten test images, since the predictions are arrays of float numbers between 0 and 1, they are *inversed transformed* to the category label, that is to the respective predicted digit (0 - 9):  \n",
    "```\n",
    "prediction: [[9.7214666e-05 8.9237624e-01 8.1143016e-03 2.9746909e-03 7.8786700e-04 6.9424585e-02 3.3270712e-03 3.2408212e-04 2.0257998e-02 2.3161303e-03]]\n",
    "```\n",
    "The closest value to 1 it is the second element in the array that corresponds to the label category for digit *1*. That is the work that `encoder.inverse_transform` does. Each prediction is compared to its respective label, if the prediction is successful the `rs` success counter is increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\trs = (encoder.inverse_transform(model.predict(test_img)) == test_lbl).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the success rate is calculated and displayed to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tpct = (rs/10000)*100\n",
    "\tprint(\"\\nModel has made\", rs, \"successful predictions out of 10000 tests (\", pct, \"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Function\n",
    "This functions checks for a model stored in the global variable *model*, if so, it proceeds to save it in an HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save():\n",
    "\tglobal model\n",
    "\t# Save model\n",
    "\tif not model:\n",
    "\t\tprint(\"There is no model!\\nPlease create/load a model first\")\n",
    "\t\treturn\n",
    "\n",
    "\tfilename = input(\"Please enter a filename: \")\n",
    "\tmodel.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read PNG Image function\n",
    "As before the fuction returns to the main menu in case of an empty model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def png_read():\n",
    "\tif not model:\n",
    "\t\tprint(\"There is no model!\\nPlease create/load a model first\")\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then asks the user for the PNG image filename. Then it converts it to grayscale coloring with the `convert(\"L\")` method. After that it gives information about the image dimensions: width and height. It also warns about not compatible image sizes to work with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tfilename = input(\"Please enter a PNG image file: \")\n",
    "\timg = Image.open(filename).convert(\"L\")\n",
    "\t\n",
    "\tprint(\"Image width (pixels): \", img.size[0], \" Image height (pixels): \", img.size[1])\n",
    "\tprint(\"\\n!Notice! Processing width times processing height must equal the amount of input neurons of a model!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *proc_width* and *proc_height* are used to scale the image. They are intialized with the same values of the image's dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tproc_width = img.size[0]\n",
    "\tproc_height = img.size[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user is asked to input new dimensions that are compatible with the model input size or press 'Enter' to leave as it is and not scale.\n",
    "\n",
    "The `img.thumbnail((proc_width,proc_height), Image.ANTIALIAS)` function call performs the scaling if the image's original dimensions were changed.\n",
    "\n",
    "The processing dimensions are displayed to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tinput_str = input(\"Please enter new image processing width: (Press enter to keep original dimension) \")\n",
    "\tif input_str:\n",
    "\t\ttry:\n",
    "\t\t\tproc_width = int(input_str)\n",
    "\t\texcept ValueError:\n",
    "\t\t\t\t# handle input error or assign default for invalid input\n",
    "\t\t\t\tprint('Invalid input')\n",
    "\t\t\t\t\n",
    "\tinput_str = input(\"Please enter new image processing height: (Press enter to keep original dimension) \")\n",
    "\tif input_str:\n",
    "\t\ttry:\n",
    "\t\t\tproc_height = int(input_str)\n",
    "\t\texcept ValueError:\n",
    "\t\t\t\t# handle input error or assign default for invalid input\n",
    "\t\t\t\tprint('Invalid input')\n",
    "\t\n",
    "\tif (proc_width != img.size[0]) or (proc_height != img.size[1]):\n",
    "\t\timg.thumbnail((proc_width,proc_height), Image.ANTIALIAS)\n",
    "\t\t\n",
    "\tprint(\"\\nProcessing width:\", proc_width, \"Processing height:\", proc_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the process to 'flatten' the image is perform multiplying the processing dimensions. For example, let's say the PNG image dimensions are 375 by 375 pixels and we have a model with 784 input neurons. The product 375x375 = 140625 is clearly not equal to the model's input 784. To solve this, since the image dimensional ratio is 1:1, we can scale the image down to 28 by 28 pixels, since 28x28 = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tone_dim =  proc_width*proc_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `im2arr` variable is defined with the pixel bytes of the scaled (or not) image. Then it is 'flatten' following a similar procedure in the previuous *train* and *test* functions: it is reshaped into a one-dimensional array of 784 columns each representing each pixel usigned byte of the image. They are divided by the scalar *255.0* to normalize the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tim2arr = np.array(img.getdata())\n",
    "\tim2arr = np.array(list(im2arr)).reshape(1, one_dim).astype(np.uint8) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the model makes a prediction, wich is reversed encoded to display more clearly the predicted class, or digit in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tpred = model.predict(im2arr)\n",
    "\trs = encoder.inverse_transform(pred)\n",
    "\tprint(\"The program predicts that the image is a:\", rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menu\n",
    "The menu displays the operation that the user can perform with this script. There are 7 items that the user can choose from. The option is stored in the *choice* variable and then parsed for function execution. The functions are the ones described in the previous sections. If an invalid option number (e.g. *0*) or other invalid character (e.g. *A*), the script yields an `Invalid option` error and asks for correct input. Option number *7* exits the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = True\n",
    "while choice:\n",
    "\tprint(\"\"\"\n",
    "\t1. Load model from HDF5 file\n",
    "\t2. Create, configure and compile model\n",
    "\t3. Train with MNIST training images\n",
    "\t4. Test against the MNIST testing images\n",
    "\t5. Save model\n",
    "\t6. Read and predict from a PNG file\n",
    "\t7. Exit\n",
    "\t\"\"\")\n",
    "\tchoice = input(\"Option: \")\n",
    "\t\n",
    "\tif choice == \"1\":\n",
    "\t\tload()\n",
    "\telif choice ==\"2\":\n",
    "\t\tconfigure()\n",
    "\telif choice ==\"3\":\n",
    "\t\ttrain()\n",
    "\telif choice==\"4\":\n",
    "\t\ttest()\n",
    "\telif choice ==\"5\":\n",
    "\t\tsave()\n",
    "\telif choice ==\"6\":\n",
    "\t\tpng_read()\n",
    "\telif choice==\"7\":\n",
    "\t\tchoice = None\n",
    "\telse:\n",
    "\t\tprint(\"Invalid option\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
